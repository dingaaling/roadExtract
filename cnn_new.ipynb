{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_new.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "WIy2zMoADG5-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "9c0845b2-c7ce-497f-89ea-d778f1a6c4c5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524693912820,
          "user_tz": 240,
          "elapsed": 15234,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QCQkna_cDLdN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S3VjHHLmDMrm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c2905c5-921f-4b57-9c2f-05b70d115a9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524707743896,
          "user_tz": 240,
          "elapsed": 3303,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os, cv2, sklearn\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ITofYDknDODA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "7f53a447-147b-43ad-b939-17caf01281ab",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524708324668,
          "user_tz": 240,
          "elapsed": 1793,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "root_dir = os.getcwd() + \"/drive/road_extract/data/sample/\"\n",
        "\n",
        "image_dir = root_dir + \"train_sample/\"\n",
        "files = os.listdir(image_dir)\n",
        "print(files)\n",
        "n = len(files)\n",
        "print(\"Loading \" + str(n) + \" train images\")\n",
        "imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
        "\n",
        "mask_dir = root_dir + \"mask_sample/\"\n",
        "files = os.listdir(mask_dir)\n",
        "print(files)\n",
        "print(\"Loading \" + str(n) + \" mask images\")\n",
        "mask_imgs = np.asarray([load_gray_image(mask_dir + files[i]) for i in range(n)])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['562_sat.jpg', '343_sat.jpg', '113_sat.jpg', '541_sat.jpg', '388_sat.jpg', '104_sat.jpg']\n",
            "Loading 6 train images\n",
            "['388_mask.png', '343_mask.png', '562_mask.png', '541_mask.png', '113_mask.png', '104_mask.png']\n",
            "Loading 6 mask images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NT6uQoTxEASV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3db533a5-ad7c-4689-91f9-cec3946b2487",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524707758363,
          "user_tz": 240,
          "elapsed": 147,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(imgs.shape)\n",
        "print(mask_imgs.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 1024, 1024, 3)\n",
            "(6, 1024, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jYnxaRNnDYOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Array of Windows and Labels"
      ]
    },
    {
      "metadata": {
        "id": "Gz83W4AWDWDU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = imgs\n",
        "Y = mask_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qVr-NjSgHY2V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
        "\n",
        "def value_to_class(v):\n",
        "    df = np.sum(v)\n",
        "    if df > foreground_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Extract patches from input images\n",
        "img_patches = [img_crop(X[i], 16, 16, 16, 0) for i in range(X.shape[0])]\n",
        "gt_patches = [img_crop_gt(Y[i], 16, 16, 16) for i in range(X.shape[0])]\n",
        "\n",
        "# Linearize list of patches\n",
        "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
        "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
        "\n",
        "X = np.asarray([img_patches[i] for i in range(len(img_patches))])\n",
        "Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LKH2j69hFkOw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "66d13618-33de-4132-bac7-c82e4ec7ad48",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524707840761,
          "user_tz": 240,
          "elapsed": 224,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24576, 16, 16, 3)\n",
            "(24576,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PPOyzZC2JnfG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "993831de-40d8-4875-ce68-9ac00a8f7db2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524707851370,
          "user_tz": 240,
          "elapsed": 244,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(X[100].shape)\n",
        "print(Y[100])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 16, 3)\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xJMVVcKKf_4M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_4d = np.zeros((len(X), 64, 64, 3))\n",
        "\n",
        "for i, window in enumerate(X):\n",
        "  X_4d[i, :, :, :] = window"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-eWpEjkrq9tV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecd9f29f-29cc-44e2-debd-7124dd59d2db",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524707888662,
          "user_tz": 240,
          "elapsed": 447,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.count_nonzero(Y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "LyB6-hrMkruk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Y_2d = np_utils.to_categorical(Y, num_classes=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pf_VqqyQk5dQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e894d593-fba2-46f9-96a6-c408059a6e40",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524708011505,
          "user_tz": 240,
          "elapsed": 225,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Y_2d.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24576, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "CG3o6nvbj3c_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pavllo Model"
      ]
    },
    {
      "metadata": {
        "id": "t0K03Z3MY4eB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "7a22b99b-808f-447c-9570-8c0fbd93ceb9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524708034515,
          "user_tz": 240,
          "elapsed": 562,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pool_size = (2, 2)\n",
        "reg = 1e-6 # L2 regularization factor (used on weights, but not biases)\n",
        "nb_classes = 2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(64, 5, 5, # 64 5x5 filters\n",
        "                        border_mode='same',\n",
        "                        input_shape=(16,16, 3)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3, # 128 3x3 filters\n",
        "                        border_mode='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, # 256 3x3 filters\n",
        "                        border_mode='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, # 256 3x3 filters\n",
        "                        border_mode='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, W_regularizer=l2(reg))) # Fully connected layer (128 neurons)\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nb_classes, W_regularizer=l2(reg)))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(16, 16, 3..., padding=\"same\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVejrGhVIoZZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "outputId": "8b7314f1-93c0-461e-a985-75aa567952bc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524708037747,
          "user_tz": 240,
          "elapsed": 228,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 64)        4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 256)         590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 997,122\n",
            "Trainable params: 997,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cLMhgSERJWW1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6lO9NwjI7gV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1349
        },
        "outputId": "6a3a23ae-02e9-4921-d061-a2e05a80cf80",
        "executionInfo": {
          "status": "error",
          "timestamp": 1524708090655,
          "user_tz": 240,
          "elapsed": 49348,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X,Y_2d, batch_size=128, epochs=10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "13568/24576 [===============>..............] - ETA: 38s - loss: 0.7247 - acc: 1.8426e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c659760fea2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nYGLqdR3DhGu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper"
      ]
    },
    {
      "metadata": {
        "id": "-1rrj23ADh3P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load_image(filename):\n",
        "    img = cv2.imread(filename)\n",
        "    resized_image = cv2.resize(img, (72,72)) \n",
        "    return img\n",
        "\n",
        "def load_gray_image(infilename):\n",
        "    img = cv2.imread(infilename)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    resized_image = cv2.resize(gray, (72,72)) \n",
        "    return gray\n",
        "\n",
        "def pad_image(data, padding):\n",
        "    \"\"\"\n",
        "    Extend the canvas of an image. Mirror boundary conditions are applied.\n",
        "    \"\"\"\n",
        "    if len(data.shape) < 3:\n",
        "        # Greyscale image (ground truth)\n",
        "        data = np.lib.pad(data, ((padding, padding), (padding, padding)), 'reflect')\n",
        "    else:\n",
        "        # RGB image\n",
        "        data = np.lib.pad(data, ((padding, padding), (padding, padding), (0,0)), 'reflect')\n",
        "    return data\n",
        "    \n",
        "def img_crop_gt(im, w, h, stride):\n",
        "    \"\"\" Crop an image into patches (this method is intended for ground truth images). \"\"\"\n",
        "    assert len(im.shape) == 2, 'Expected greyscale image.'\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    for i in range(0,imgheight,stride):\n",
        "        for j in range(0,imgwidth,stride):\n",
        "            im_patch = im[j:j+w, i:i+h]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches\n",
        "    \n",
        "def img_crop(im, w, h, stride, padding):\n",
        "    \"\"\" Crop an image into patches, taking into account mirror boundary conditions. \"\"\"\n",
        "    assert len(im.shape) == 3, 'Expected RGB image.'\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    im = np.lib.pad(im, ((padding, padding), (padding, padding), (0,0)), 'reflect')\n",
        "    for i in range(padding,imgheight+padding,stride):\n",
        "        for j in range(padding,imgwidth+padding,stride):\n",
        "            im_patch = im[j-padding:j+w+padding, i-padding:i+h+padding, :]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches\n",
        "    \n",
        "def create_patches(X, patch_size, stride, padding):\n",
        "    img_patches = np.asarray([img_crop(X[i], patch_size, patch_size, stride, padding) for i in range(X.shape[0])])\n",
        "    # Linearize list\n",
        "    img_patches = img_patches.reshape(-1, img_patches.shape[2], img_patches.shape[3], img_patches.shape[4])\n",
        "    return img_patches\n",
        "    \n",
        "def create_patches_gt(X, patch_size, stride):\n",
        "    img_patches = np.asarray([img_crop_gt(X[i], patch_size, patch_size, stride) for i in range(X.shape[0])])\n",
        "    # Linearize list\n",
        "    img_patches = img_patches.reshape(-1, img_patches.shape[2], img_patches.shape[3])\n",
        "    return img_patches\n",
        "    \n",
        "def group_patches(patches, num_images):\n",
        "    return patches.reshape(num_images, -1)\n",
        "\n",
        "def extract_img_features(filename, stride):\n",
        "    img = load_image(filename)\n",
        "    img_patches = img_crop(img, patch_size, patch_size, stride, padding)\n",
        "    X = np.asarray([img_patches[i] for i in range(len(img_patches))])\n",
        "    return X\n",
        "\n",
        "def mask_to_submission_strings(model, image_filename):\n",
        "    \"\"\" Reads a single image and outputs the strings that should go into the submission file. \"\"\"\n",
        "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
        "    Xi = load_image(image_filename)\n",
        "    Xi = Xi.reshape(1, Xi.shape[0], Xi.shape[1], Xi.shape[2])\n",
        "    Zi = model.classify(Xi)\n",
        "    Zi = Zi.reshape(-1)\n",
        "    patch_size = 16\n",
        "    nb = 0\n",
        "    print(\"Processing \" + image_filename)\n",
        "    for j in range(0, Xi.shape[2], patch_size):\n",
        "        for i in range(0, Xi.shape[1], patch_size):\n",
        "            label = int(Zi[nb])\n",
        "            nb += 1\n",
        "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}