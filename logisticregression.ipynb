{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(fileName):\n",
    "    return mpimg.imread(fileName)\n",
    "\n",
    "def grey_scale_conversion(img):\n",
    "    new_img = np.zeros((img.shape[0],img.shape[1]))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i,j,1] == 1.0:\n",
    "                new_img[i,j] = 1\n",
    "    return new_img\n",
    "\n",
    "def display_image(fileName):\n",
    "    imgPlot = plt.imshow(fileName)\n",
    "    plt.show()\n",
    "\n",
    "def group_patches(patches, num_images):\n",
    "    return patches.reshape(num_images, -1)\n",
    "\n",
    "def feature_extract(imgPatch):\n",
    "\n",
    "    mean = np.mean(imgPatch, axis=(0,1))\n",
    "    std = np.std(imgPatch, axis=(0,1))\n",
    "    features = np.append(mean, std)\n",
    "    return features\n",
    "\n",
    "def poly_fit(X):\n",
    "    \"\"\"\n",
    "    Fit the dataset using a polynomial basis.\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(4, interaction_only=False)\n",
    "    return poly.fit_transform(X)\n",
    "\n",
    "def img_crop(img, w, h, stride, padding):\n",
    "\n",
    "    cropList = []\n",
    "\n",
    "    imgWidth, imgHeight =img.shape[0], img.shape[1]\n",
    "    img = np.lib.pad(img, ((padding, padding), (padding, padding), (0,0)), \"reflect\")\n",
    "\n",
    "    for i in range(padding,imgHeight+padding,stride):\n",
    "        for j in range(padding,imgWidth+padding,stride):\n",
    "            im_patch = img[j-padding:j+w+padding, i-padding:i+h+padding, :]\n",
    "            cropList.append(im_patch)\n",
    "    return cropList\n",
    "\n",
    "def img_crop_gt(im, w, h, stride):\n",
    "    \"\"\" Crop an image into patches (this method is intended for ground truth images). \"\"\"\n",
    "    assert len(im.shape) == 2, 'Expected greyscale image.'\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    for i in range(0,imgheight,stride):\n",
    "        for j in range(0,imgwidth,stride):\n",
    "            im_patch = im[j:j+w, i:i+h]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "    df = np.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def train(Y, X):\n",
    "    \"\"\"\n",
    "    Train this model.\n",
    "    \"\"\"\n",
    "\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "    def value_to_class(v):\n",
    "        df = np.sum(v)\n",
    "        if df > foreground_threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Extract patches from input images\n",
    "    img_patches = [img_crop(X[i], 16, 16, 3, 0) for i in range(X.shape[0])]\n",
    "    gt_patches = [img_crop_gt(grey_scale_conversion(Y[i]), 16, 16, 3) for i in range(X.shape[0])]\n",
    "\n",
    "    # Linearize list of patches\n",
    "    img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "    gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "\n",
    "    X = np.asarray([feature_extract(img_patches[i]) for i in range(len(img_patches))])\n",
    "    Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])\n",
    "    \n",
    "    X = poly_fit(X)\n",
    "    print('start fitting')\n",
    "    logreg.fit(X, Y)\n",
    "\n",
    "    print('Training completed')\n",
    "\n",
    "\n",
    "def classify(X):\n",
    "    \"\"\"\n",
    "    Classify an unseen set of samples.\n",
    "    This method must be called after \"train\".\n",
    "    Returns a list of predictions.\n",
    "    \"\"\"\n",
    "    img_patches = [img_crop(X[i], 16, 16, 3, 0) for i in range(X.shape[0])]\n",
    "    img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "    X = np.asarray([feature_extract(img_patches[i]) for i in range(len(img_patches))])\n",
    "    X = poly_fit(X)\n",
    "    print('start predicting')\n",
    "    Z = logreg.predict(X)\n",
    "    # Regroup patches into images\n",
    "    print('prediction completed')\n",
    "    return group_patches(Z, X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(X, patch_size, stride, padding):\n",
    "    img_patches = np.asarray([img_crop(X[i], patch_size, patch_size, stride, padding) for i in range(X.shape[0])])\n",
    "    # Linearize list\n",
    "    img_patches = img_patches.reshape(-1, img_patches.shape[2], img_patches.shape[3], img_patches.shape[4])\n",
    "    return img_patches\n",
    "    \n",
    "def create_patches_gt(X, patch_size, stride):\n",
    "#     gt_patches = [img_crop_gt(grey_scale_conversion(Y[i]), 16, 16, 3) for i in range(X.shape[0])]\n",
    "#     gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    img_patches = np.asarray([img_crop_gt(grey_scale_conversion(X[i]), patch_size, patch_size, stride) for i in range(X.shape[0])])\n",
    "    # Linearize list\n",
    "    print(img_patches.shape)\n",
    "    img_patches = img_patches.reshape(-1)\n",
    "    print(img_patches.shape)\n",
    "    return img_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_results(y, y_test):\n",
    "    \"\"\"\n",
    "    Get the ratio of correct answers.\n",
    "    \"\"\"\n",
    "    y = y.reshape(-1) # Linearize\n",
    "    y_test = y_test.reshape(-1) # Linearize\n",
    "    diff = y - y_test\n",
    "    correct = np.sum(diff == 0)\n",
    "    return correct / y_test.size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 5 train images\n",
      "Loading 5 mask images\n",
      "start fitting\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    root_dir = os.getcwd() + \"/sample/\"\n",
    "    \n",
    "    image_dir = root_dir + \"train_sample/\"\n",
    "    files = os.listdir(image_dir)\n",
    "    n = len(files)\n",
    "    print(\"Loading \" + str(n) + \" train images\")\n",
    "    imgs = np.asarray([load_image(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "    mask_dir = root_dir + \"mask_sample/\"\n",
    "    files = os.listdir(mask_dir)\n",
    "    print(\"Loading \" + str(n) + \" mask images\")\n",
    "    mask_imgs = np.asarray([load_image(mask_dir + files[i]) for i in range(n)])\n",
    "    \n",
    "    logreg = linear_model.LogisticRegression(C=1e5)\n",
    "    train(mask_imgs, imgs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predicting\n",
      "prediction completed\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.getcwd() + \"/data/road-train-2+valid/sample_valid/\"\n",
    "image_dir = root_dir + \"img/\"\n",
    "mask_dir = root_dir + \"mask/\"\n",
    "\n",
    "files = os.listdir(image_dir)\n",
    "test_imgs = np.asarray([load_image(image_dir + files[0])])\n",
    "files = os.listdir(mask_dir)\n",
    "test_mask = np.asarray([load_image(mask_dir + files[0])])\n",
    "Z = classify(test_imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9723590164495058\n"
     ]
    }
   ],
   "source": [
    "y_te = test_mask\n",
    "# img_patches_gt = create_patches_gt(y_te, 16, 3)\n",
    "# y_real = np.mean(img_patches_gt, axis=(1, 2)) > 0.25\n",
    "gt_patches = [img_crop_gt(grey_scale_conversion(y_te[i]), 16, 16, 3) for i in range(y_te.shape[0])]\n",
    "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])\n",
    "result = get_classification_results(Y, Z) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuhgekroYHpK6GB6SuhgekroYHpK6/D+1C/6L4thRlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e38f160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc2HSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e475668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_dir = os.getcwd() + \"/data/road-train-2+valid/sample/\"\n",
    "image_dir = root_dir + \"mask_sample/104_mask.png\"\n",
    "img = load_image(image_dir)\n",
    "\n",
    "new_img = grey_scale_conversion(img)\n",
    "plt.imshow(new_img)\n",
    "plt.show()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
