{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imageLoad.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "md6hhAuzL-Zd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "b3902e70-7174-4cf0-d9b4-7ea12601d4cd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525287147715,
          "user_tz": 240,
          "elapsed": 11508,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XcfdBBHQMA9l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gezy4cwyMCZr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "248d5e98-130f-450e-f603-576baebad4e4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525288065118,
          "user_tz": 240,
          "elapsed": 3495,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os, cv2, sklearn\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JPFh96EIMEbB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1643
        },
        "outputId": "fbf1d74a-b719-4437-ce00-b8d6cddf3d10",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525288086074,
          "user_tz": 240,
          "elapsed": 6235,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "root_dir = os.getcwd() + \"/drive/road_extract/data/sample/\"\n",
        "image_dir = root_dir + \"train_sample/\"\n",
        "mask_dir = root_dir + \"mask_sample/\"\n",
        "\n",
        "imgs, mask_imgs = [], []\n",
        "\n",
        "\n",
        "for im in os.listdir(image_dir):\n",
        "  imPath = image_dir + im\n",
        "  maskPath = mask_dir + im.split('_')[0] + \"_mask.png\"\n",
        "  \n",
        "  imgs.append(load_image(imPath))\n",
        "  mask_imgs.append(load_gray_image(maskPath))\n",
        "  \n",
        "  print(imPath, maskPath)\n",
        "\n",
        "\n",
        "imgs = np.asarray(imgs)\n",
        "mask_imgs = np.asarray(mask_imgs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/road_extract/data/sample/train_sample/104_sat.jpg /content/drive/road_extract/data/sample/mask_sample/104_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/541_sat.jpg /content/drive/road_extract/data/sample/mask_sample/541_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/388_sat.jpg /content/drive/road_extract/data/sample/mask_sample/388_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/627_sat.jpg /content/drive/road_extract/data/sample/mask_sample/627_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/655_sat.jpg /content/drive/road_extract/data/sample/mask_sample/655_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/602_sat.jpg /content/drive/road_extract/data/sample/mask_sample/602_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/113_sat.jpg /content/drive/road_extract/data/sample/mask_sample/113_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/951_sat.jpg /content/drive/road_extract/data/sample/mask_sample/951_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/343_sat.jpg /content/drive/road_extract/data/sample/mask_sample/343_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/562_sat.jpg /content/drive/road_extract/data/sample/mask_sample/562_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/1934_sat.jpg /content/drive/road_extract/data/sample/mask_sample/1934_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/1849_sat.jpg /content/drive/road_extract/data/sample/mask_sample/1849_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/1054_sat.jpg /content/drive/road_extract/data/sample/mask_sample/1054_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/2647_sat.jpg /content/drive/road_extract/data/sample/mask_sample/2647_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/2129_sat.jpg /content/drive/road_extract/data/sample/mask_sample/2129_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/2495_sat.jpg /content/drive/road_extract/data/sample/mask_sample/2495_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/2730_sat.jpg /content/drive/road_extract/data/sample/mask_sample/2730_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/2262_sat.jpg /content/drive/road_extract/data/sample/mask_sample/2262_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/2667_sat.jpg /content/drive/road_extract/data/sample/mask_sample/2667_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/1945_sat.jpg /content/drive/road_extract/data/sample/mask_sample/1945_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/3594_sat.jpg /content/drive/road_extract/data/sample/mask_sample/3594_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/4163_sat.jpg /content/drive/road_extract/data/sample/mask_sample/4163_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/3530_sat.jpg /content/drive/road_extract/data/sample/mask_sample/3530_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/3280_sat.jpg /content/drive/road_extract/data/sample/mask_sample/3280_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/3602_sat.jpg /content/drive/road_extract/data/sample/mask_sample/3602_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/3452_sat.jpg /content/drive/road_extract/data/sample/mask_sample/3452_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/4131_sat.jpg /content/drive/road_extract/data/sample/mask_sample/4131_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/3573_sat.jpg /content/drive/road_extract/data/sample/mask_sample/3573_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/4227_sat.jpg /content/drive/road_extract/data/sample/mask_sample/4227_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/4209_sat.jpg /content/drive/road_extract/data/sample/mask_sample/4209_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5501_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5501_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5740_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5740_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/4301_sat.jpg /content/drive/road_extract/data/sample/mask_sample/4301_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/4903_sat.jpg /content/drive/road_extract/data/sample/mask_sample/4903_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5386_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5386_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5523_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5523_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5279_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5279_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5668_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5668_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5415_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5415_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5555_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5555_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/5947_sat.jpg /content/drive/road_extract/data/sample/mask_sample/5947_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/7011_sat.jpg /content/drive/road_extract/data/sample/mask_sample/7011_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/6294_sat.jpg /content/drive/road_extract/data/sample/mask_sample/6294_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/7372_sat.jpg /content/drive/road_extract/data/sample/mask_sample/7372_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/6696_sat.jpg /content/drive/road_extract/data/sample/mask_sample/6696_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/6281_sat.jpg /content/drive/road_extract/data/sample/mask_sample/6281_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/7046_sat.jpg /content/drive/road_extract/data/sample/mask_sample/7046_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/6415_sat.jpg /content/drive/road_extract/data/sample/mask_sample/6415_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/6383_sat.jpg /content/drive/road_extract/data/sample/mask_sample/6383_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/6822_sat.jpg /content/drive/road_extract/data/sample/mask_sample/6822_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/7817_sat.jpg /content/drive/road_extract/data/sample/mask_sample/7817_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8078_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8078_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8048_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8048_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8162_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8162_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8840_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8840_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8317_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8317_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8804_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8804_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8646_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8646_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8710_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8710_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8584_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8584_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/9937_sat.jpg /content/drive/road_extract/data/sample/mask_sample/9937_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8980_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8980_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/8971_sat.jpg /content/drive/road_extract/data/sample/mask_sample/8971_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/9663_sat.jpg /content/drive/road_extract/data/sample/mask_sample/9663_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/10246_sat.jpg /content/drive/road_extract/data/sample/mask_sample/10246_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/9872_sat.jpg /content/drive/road_extract/data/sample/mask_sample/9872_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/10466_sat.jpg /content/drive/road_extract/data/sample/mask_sample/10466_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/10255_sat.jpg /content/drive/road_extract/data/sample/mask_sample/10255_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/9339_sat.jpg /content/drive/road_extract/data/sample/mask_sample/9339_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/9433_sat.jpg /content/drive/road_extract/data/sample/mask_sample/9433_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/11545_sat.jpg /content/drive/road_extract/data/sample/mask_sample/11545_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/11570_sat.jpg /content/drive/road_extract/data/sample/mask_sample/11570_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/10716_sat.jpg /content/drive/road_extract/data/sample/mask_sample/10716_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/10802_sat.jpg /content/drive/road_extract/data/sample/mask_sample/10802_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/10486_sat.jpg /content/drive/road_extract/data/sample/mask_sample/10486_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/11480_sat.jpg /content/drive/road_extract/data/sample/mask_sample/11480_mask.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/road_extract/data/sample/train_sample/12810_sat.jpg /content/drive/road_extract/data/sample/mask_sample/12810_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/12347_sat.jpg /content/drive/road_extract/data/sample/mask_sample/12347_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/12023_sat.jpg /content/drive/road_extract/data/sample/mask_sample/12023_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/11168_sat.jpg /content/drive/road_extract/data/sample/mask_sample/11168_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/14361_sat.jpg /content/drive/road_extract/data/sample/mask_sample/14361_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/15347_sat.jpg /content/drive/road_extract/data/sample/mask_sample/15347_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/13635_sat.jpg /content/drive/road_extract/data/sample/mask_sample/13635_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/13870_sat.jpg /content/drive/road_extract/data/sample/mask_sample/13870_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/15003_sat.jpg /content/drive/road_extract/data/sample/mask_sample/15003_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/14958_sat.jpg /content/drive/road_extract/data/sample/mask_sample/14958_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/15237_sat.jpg /content/drive/road_extract/data/sample/mask_sample/15237_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/12959_sat.jpg /content/drive/road_extract/data/sample/mask_sample/12959_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/13945_sat.jpg /content/drive/road_extract/data/sample/mask_sample/13945_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/13148_sat.jpg /content/drive/road_extract/data/sample/mask_sample/13148_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/17596_sat.jpg /content/drive/road_extract/data/sample/mask_sample/17596_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/16422_sat.jpg /content/drive/road_extract/data/sample/mask_sample/16422_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/17193_sat.jpg /content/drive/road_extract/data/sample/mask_sample/17193_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/16754_sat.jpg /content/drive/road_extract/data/sample/mask_sample/16754_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/16493_sat.jpg /content/drive/road_extract/data/sample/mask_sample/16493_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/15833_sat.jpg /content/drive/road_extract/data/sample/mask_sample/15833_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/17304_sat.jpg /content/drive/road_extract/data/sample/mask_sample/17304_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/16577_sat.jpg /content/drive/road_extract/data/sample/mask_sample/16577_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/17121_sat.jpg /content/drive/road_extract/data/sample/mask_sample/17121_mask.png\n",
            "/content/drive/road_extract/data/sample/train_sample/17324_sat.jpg /content/drive/road_extract/data/sample/mask_sample/17324_mask.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4ZJEtfzfOTiA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "64a9500e-7c4c-498a-9c0d-e744b9f44e59",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525288093377,
          "user_tz": 240,
          "elapsed": 270,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(imgs.shape)\n",
        "print(mask_imgs.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1024, 1024, 3)\n",
            "(100, 1024, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTzP8jDZPpjg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Array of Windows and Labels"
      ]
    },
    {
      "metadata": {
        "id": "9iVR_FU3PeRy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = imgs\n",
        "Y = mask_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8B4DWYC-Pq6C",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
        "\n",
        "def value_to_class(v):\n",
        "    df = np.sum(v)\n",
        "    if df > foreground_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Extract patches from input images\n",
        "img_patches = [img_crop(X[i], 16, 16, 16, 0) for i in range(X.shape[0])]\n",
        "gt_patches = [img_crop_gt(Y[i], 16, 16, 16) for i in range(X.shape[0])]\n",
        "\n",
        "# Linearize list of patches\n",
        "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
        "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
        "\n",
        "X = np.asarray([img_patches[i] for i in range(len(img_patches))])\n",
        "Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihfBV1aRQXFM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "90b0e6c3-1a88-4e26-b307-0f16eca2ffd4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525288113578,
          "user_tz": 240,
          "elapsed": 307,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(409600, 16, 16, 3)\n",
            "(409600,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwU3f864PuPq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Y_2d = np_utils.to_categorical(Y, num_classes=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJTu7OvHPxW7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "9a44f4fb-8198-4f94-d5fa-9bd09bd9bec9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525288183869,
          "user_tz": 240,
          "elapsed": 267,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.count_nonzero(Y_2d[:,1]))\n",
        "print(Y_2d.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37857\n",
            "(409600, 2)\n",
            "(409600, 16, 16, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QI_5KL7NP8EB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pavllo Model"
      ]
    },
    {
      "metadata": {
        "id": "wPEBfk_0P9FC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "d0647538-cd09-4128-bd76-be85bc4d9759",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525288199905,
          "user_tz": 240,
          "elapsed": 524,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pool_size = (2, 2)\n",
        "reg = 1e-6 # L2 regularization factor (used on weights, but not biases)\n",
        "nb_classes = 2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(64, 5, 5, # 64 5x5 filters\n",
        "                        border_mode='same',\n",
        "                        input_shape=(16,16, 3)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3, # 128 3x3 filters\n",
        "                        border_mode='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, # 256 3x3 filters\n",
        "                        border_mode='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, # 256 3x3 filters\n",
        "                        border_mode='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, W_regularizer=l2(reg))) # Fully connected layer (128 neurons)\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nb_classes, W_regularizer=l2(reg)))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(16, 16, 3..., padding=\"same\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZoVAHiLUP_U7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "outputId": "19632d85-c0d7-4529-9291-057527988676",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525288202734,
          "user_tz": 240,
          "elapsed": 364,
          "user": {
            "displayName": "Jennifer Ding",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102188744832786998041"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         590080    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 997,122\n",
            "Trainable params: 997,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ecRtXPZKQEOD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMGdhKmPQF-R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7fd37083-fe28-4e11-8311-b9fca2123bc2"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X,Y_2d, batch_size=128, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 69504/409600 [====>.........................] - ETA: 20:59 - loss: 1.4820 - acc: 2.1581e-05"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s_VQrbf-N1rD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "1RtWqe52N3Cx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load_image(filename):\n",
        "    img = cv2.imread(filename)\n",
        "    resized_image = cv2.resize(img, (72,72)) \n",
        "    return img\n",
        "\n",
        "def load_gray_image(infilename):\n",
        "    img = cv2.imread(infilename)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    resized_image = cv2.resize(gray, (72,72)) \n",
        "    return gray\n",
        "\n",
        "def pad_image(data, padding):\n",
        "    \"\"\"\n",
        "    Extend the canvas of an image. Mirror boundary conditions are applied.\n",
        "    \"\"\"\n",
        "    if len(data.shape) < 3:\n",
        "        # Greyscale image (ground truth)\n",
        "        data = np.lib.pad(data, ((padding, padding), (padding, padding)), 'reflect')\n",
        "    else:\n",
        "        # RGB image\n",
        "        data = np.lib.pad(data, ((padding, padding), (padding, padding), (0,0)), 'reflect')\n",
        "    return data\n",
        "    \n",
        "def img_crop_gt(im, w, h, stride):\n",
        "    \"\"\" Crop an image into patches (this method is intended for ground truth images). \"\"\"\n",
        "    assert len(im.shape) == 2, 'Expected greyscale image.'\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    for i in range(0,imgheight,stride):\n",
        "        for j in range(0,imgwidth,stride):\n",
        "            im_patch = im[j:j+w, i:i+h]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches\n",
        "    \n",
        "def img_crop(im, w, h, stride, padding):\n",
        "    \"\"\" Crop an image into patches, taking into account mirror boundary conditions. \"\"\"\n",
        "    assert len(im.shape) == 3, 'Expected RGB image.'\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    im = np.lib.pad(im, ((padding, padding), (padding, padding), (0,0)), 'reflect')\n",
        "    for i in range(padding,imgheight+padding,stride):\n",
        "        for j in range(padding,imgwidth+padding,stride):\n",
        "            im_patch = im[j-padding:j+w+padding, i-padding:i+h+padding, :]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches\n",
        "    \n",
        "def create_patches(X, patch_size, stride, padding):\n",
        "    img_patches = np.asarray([img_crop(X[i], patch_size, patch_size, stride, padding) for i in range(X.shape[0])])\n",
        "    # Linearize list\n",
        "    img_patches = img_patches.reshape(-1, img_patches.shape[2], img_patches.shape[3], img_patches.shape[4])\n",
        "    return img_patches\n",
        "    \n",
        "def create_patches_gt(X, patch_size, stride):\n",
        "    img_patches = np.asarray([img_crop_gt(X[i], patch_size, patch_size, stride) for i in range(X.shape[0])])\n",
        "    # Linearize list\n",
        "    img_patches = img_patches.reshape(-1, img_patches.shape[2], img_patches.shape[3])\n",
        "    return img_patches\n",
        "    \n",
        "def group_patches(patches, num_images):\n",
        "    return patches.reshape(num_images, -1)\n",
        "\n",
        "def extract_img_features(filename, stride):\n",
        "    img = load_image(filename)\n",
        "    img_patches = img_crop(img, patch_size, patch_size, stride, padding)\n",
        "    X = np.asarray([img_patches[i] for i in range(len(img_patches))])\n",
        "    return X\n",
        "\n",
        "def mask_to_submission_strings(model, image_filename):\n",
        "    \"\"\" Reads a single image and outputs the strings that should go into the submission file. \"\"\"\n",
        "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
        "    Xi = load_image(image_filename)\n",
        "    Xi = Xi.reshape(1, Xi.shape[0], Xi.shape[1], Xi.shape[2])\n",
        "    Zi = model.classify(Xi)\n",
        "    Zi = Zi.reshape(-1)\n",
        "    patch_size = 16\n",
        "    nb = 0\n",
        "    print(\"Processing \" + image_filename)\n",
        "    for j in range(0, Xi.shape[2], patch_size):\n",
        "        for i in range(0, Xi.shape[1], patch_size):\n",
        "            label = int(Zi[nb])\n",
        "            nb += 1\n",
        "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}